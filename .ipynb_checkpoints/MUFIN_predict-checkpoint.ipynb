{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcb8a80-6125-47d9-9e03-e614ea8e17fc",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65846a34-2ffd-4c07-aff3-c42df0fbf30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir=\"/scratch/cse/phd/anz198717/XC\"\n",
    "corpus_dataset=\"DummyData\"\n",
    "version=\"sample_pos\"\n",
    "model_type=\"PreTrainedMufinMultiModal\"\n",
    "img_model=\"ViT\"\n",
    "txt_model=\"sentencebert\"\n",
    "ranker=\"MufinXAttnRankerpp\"\n",
    "corpus_dset=f\"{work_dir}/Corpus/{corpus_dataset}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74452bf6-9d3f-469b-beed-9f7ac5add12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "import sys\n",
    "site.addsitedir(f\"{work_dir}/programs/ExtremeMethods\")\n",
    "import os\n",
    "os.environ['KEEP_TOP_K'] = \"-1\"\n",
    "os.environ['RESTRICTMEM'] = \"0\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import mufin as mn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a337667-f9a7-44e1-8b72-dc11c9ee5f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(A=0.55, B=1.5, accumulate=1, batch_size=512, bucket=1, data_dir='/scratch/cse/phd/anz198717/XC/Corpus/DummyData', data_path=None, dropout=0.2, encoder_init=None, filter_labels='filter_labels_test.txt', head_dims=1024, img_model='ViT', keep_all=True, lbl_indices=array([     0,      1,      2, ..., 303293, 303294, 303295]), margin=0.2, max_worker_thread=6, model_dir='/scratch/cse/phd/anz198717/XC/models/384-BIN-IMG-AmazonTitles-300K/PreTrainedMultiModalSiameseXC/v_Final', model_fname='PreTrainedMufinMultiModal', model_out_name='model.pkl', module=1, n_heads=2, n_layer=1, neg_sample=2, num_labels=303296, num_workers=6, optim='Adam', prefetch_factor=2, project_dim=128, ranker='MufinXAttnRankerpp', result_dir='/scratch/cse/phd/anz198717/XC/Corpus/DummyData/temp', top_k=100, txt_model='sentencebert', validate=False)\n"
     ]
    }
   ],
   "source": [
    "sys.argv = f\"MUFIN\".split()\n",
    "import argparse\n",
    "parser = argparse.ArgumentParser(description='Inference')\n",
    "params = parser.parse_args()\n",
    "params.A = 0.55\n",
    "params.B = 1.5\n",
    "\n",
    "params.data_dir = corpus_dset\n",
    "params.img_model = img_model\n",
    "params.filter_labels = \"filter_labels_test.txt\"\n",
    "params.txt_model = txt_model\n",
    "params.img_model = img_model\n",
    "params.data_path = None\n",
    "params.module = 1\n",
    "params.max_worker_thread = 6\n",
    "params.bucket = 1\n",
    "params.accumulate = 1\n",
    "params.margin = 0.2\n",
    "params.neg_sample = 2\n",
    "params.project_dim = 128\n",
    "params.n_heads = 2\n",
    "params.head_dims = 1024\n",
    "params.n_layer = 1\n",
    "params.dropout = 0.2\n",
    "params.keep_all = True\n",
    "params.batch_size = 512\n",
    "params.num_workers = 6\n",
    "params.validate = False\n",
    "params.model_out_name = \"model.pkl\"\n",
    "params.optim = \"Adam\"\n",
    "params.prefetch_factor = 2\n",
    "\"\"\"\n",
    "Adjust according to need\n",
    "\"\"\"\n",
    "params.ranker = ranker\n",
    "params.model_dir = f\"{work_dir}/models/384-BIN-IMG-AmazonTitles-300K/PreTrainedMultiModalSiameseXC/v_Final\"\n",
    "params.result_dir = f\"{corpus_dset}/temp\"\n",
    "params.model_fname = model_type\n",
    "params.num_labels = 303296\n",
    "params.top_k = 100\n",
    "params.lbl_indices = np.arange(params.num_labels)\n",
    "\n",
    "ext = \"vect\" if \"PreTrained\" in model_type else \"bin\"\n",
    "params.encoder_init = None if \"PreTrained\" in model_type else \"module3/encoder.pkl\"\n",
    "os.makedirs(params.model_dir, exist_ok=True)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc6f0b-91b3-4d67-9f44-53d79c5d2ab6",
   "metadata": {},
   "source": [
    "### M1 Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc211e4b-a465-4e6f-bdc8-5c970ce30848",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.module = 1\n",
    "params.num_epoch = 200\n",
    "params.surrogate_warm = 20\n",
    "params.lr = 0.02\n",
    "params.at_least = 5\n",
    "params.ignore_img = False\n",
    "params.ignore_txt = False\n",
    "params.max_csim = 0.9\n",
    "params.max_worker_thread = 10\n",
    "params.min_leaf_sz = 32\n",
    "params.min_splits = -1\n",
    "params.sampling = True\n",
    "params.warm_start = 1\n",
    "params.multi_pos = 1\n",
    "params.preload = False\n",
    "params.surrogate_warm = 1000\n",
    "\n",
    "mode = \"test\"\n",
    "net = mn.construct_network(params)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d82770-693f-4fff-abce-587b2e5261a8",
   "metadata": {},
   "source": [
    "#### TRAIN ONLY IF TRAIN AND LABEL SET IS DIFFERENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8c990-880f-43e0-8c77-33cac4fd580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.retrain(corpus_dset, f\"temp/train.img.{ext}\", \"temp/train.txt.seq.memmap\", \"trn_X_Y.txt\", f\"temp/label.img.{ext}\", \"temp/label.txt.seq.memmap\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993644de-0874-420d-bbf2-ba6df288b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.module = 2\n",
    "shorty_path = f\"{params.result_dir}/module2\"\n",
    "os.makedirs(shorty_path, exist_ok=True)\n",
    "net = mn.construct_network(params)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)\n",
    "tst_mat = model.predict(corpus_dset, f\"temp/{mode}.img.{ext}\", f\"temp/{mode}.txt.seq.memmap\", None, None, None)\n",
    "sp.save_npz(os.path.join(shorty_path, f\"{mode}.npz\"), tst_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bc75c-adb7-4189-8e7d-f60a7318f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "params.module = 3\n",
    "\n",
    "emb_path = f\"{params.result_dir}/module3\"\n",
    "os.makedirs(emb_path, exist_ok=True)\n",
    "\n",
    "net = mn.construct_network(params)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)\n",
    "\n",
    "# tst_emb = model.extract(corpus_dset, f\"temp/{mode}.img.{ext}\", f\"temp/{mode}.txt.seq.memmap\")\n",
    "# for key in tst_emb.keys():\n",
    "#     tst_emb[key].save(emb_path+f\"/{mode}.{key}\")\n",
    "\n",
    "# tst_emb = model.extract(corpus_dset, f\"temp/label.img.{ext}\", f\"temp/label.txt.seq.memmap\")\n",
    "for key in tst_emb.keys():\n",
    "    tst_emb[key].save(emb_path+f\"/label.{key}\")\n",
    "    \n",
    "# encoder = model.extract_encoder()\n",
    "# torch.save(encoder, os.path.join(emb_path, \"encoder.pkl\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85310207-4b1b-4d80-963c-bbac9d01d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.module = 4\n",
    "params.sample_neg = 2\n",
    "params.sample_pos = 12\n",
    "params.cosine_margin = 0.5\n",
    "params.ranker_project_dim = 128\n",
    "params.lr = 0.02\n",
    "params.lr_mf_enc = 0.01\n",
    "params.lr_mf_clf = 0.1\n",
    "params.boosting = False\n",
    "params.sampling = True\n",
    "params.ranker_warm = 1000\n",
    "params.num_epochs = 20\n",
    "params.ranker = \"MufinXAttnRanker\"\n",
    "emb_path = f\"{params.result_dir}/module4\"\n",
    "params.model_out_name = f\"model_XAttnRanker.pkl\"\n",
    "\n",
    "os.makedirs(emb_path, exist_ok=True)\n",
    "\n",
    "net = mn.construct_network(params)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)\n",
    "score_mat = model.predict(corpus_dset, f\"module3/test.img.pretrained\", \"module3/test.txt.pretrained\", None, f\"module3/label.img.pretrained\", \"module3/label.txt.pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "5025a5ff-a964-4bd7-81f2-44d99cef07ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cosine scheudler\n",
      "IMG:temp/test.img.vect(read_full=True)\n",
      "IMG:temp/label.img.vect(read_full=True)\n",
      "Loading model..\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "docs: 100%|██████████| 509/509 [00:21<00:00, 34.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                       \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lbls: 100%|██████████| 593/593 [00:21<00:00, 28.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                               \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 1018/1018 [02:09<00:00, 11.74it/s]\n",
      "26053844 26053600\n"
     ]
    }
   ],
   "source": [
    "params.module = 4\n",
    "params.sample_neg = 2\n",
    "params.sample_pos = 12\n",
    "params.cosine_margin = 0.5\n",
    "params.ranker_project_dim = 128\n",
    "params.lr = 0.02\n",
    "params.lr_mf_enc = 0.01\n",
    "params.lr_mf_clf = 0.1\n",
    "params.boosting = False\n",
    "params.sampling = True\n",
    "params.ranker_warm = 1000\n",
    "params.num_epochs = 20\n",
    "params.ranker = \"MufinXAttnRankerpp\"\n",
    "emb_path = f\"{params.result_dir}/module4\"\n",
    "params.model_out_name = f\"model_XAttnRankerpp.pkl\"\n",
    "\n",
    "os.makedirs(emb_path, exist_ok=True)\n",
    "\n",
    "net = mn.construct_network(params)\n",
    "# print(net)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)\n",
    "# score_mat = model.predict(corpus_dset, f\"temp/test.img.{ext}\", \"temp/test.txt.seq.memmap\", None,  f\"temp/label.img.{ext}\", \"temp/label.txt.seq.memmap\")\n",
    "score_mat = model.predict(corpus_dset, f\"temp/test.img.{ext}\", None, None,  f\"temp/label.img.{ext}\", None)\n",
    "# score_mat = model.predict(corpus_dset, None, \"temp/test.txt.seq.memmap\", None, None, \"temp/label.txt.seq.memmap\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4199453c-6577-48a6-9697-9c862059e2e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UTILS:FILTER:Loading from pre-build file\n",
      "UTILS:FILTER:Overlap is:586902\n"
     ]
    }
   ],
   "source": [
    "from xclib.evaluation import xc_metrics as xm\n",
    "from xc.libs.utils import load_overlap\n",
    "tst_y = du.read_sparse_file(f\"{corpus_dset}/tst_X_Y.txt\")\n",
    "acc = xm.Metrics(tst_y)\n",
    "docs, lbls = load_overlap(corpus_dset, params.lbl_indices, \"filter_labels_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "16c8354f-e499-475f-a73a-4c17e45c90f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluations(score_dict, acc, docs, lbls, al=0.9):\n",
    "    m2 = score_dict[\"module4/m2\"]\n",
    "    m4 = score_dict[\"module4/m4\"]\n",
    "    m2[docs, lbls] = 0\n",
    "    m2.eliminate_zeros()\n",
    "    print(acc.eval(m2, K=5))\n",
    "    m4[docs, lbls] = 0\n",
    "    m4.eliminate_zeros()\n",
    "    print(acc.eval(m4, K=5))\n",
    "    for alpha in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "        mat = m2.copy().multiply(alpha) + m4.copy().multiply(1-alpha)\n",
    "        print(f\"alpha={alpha}\")\n",
    "        print(acc.eval(mat, K=5))\n",
    "    return m2.copy().multiply(al) + m4.copy().multiply(1-al)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dad1c8f1-5678-43e6-b21b-9643e790e275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0.43053935, 0.37742769, 0.34095736, 0.31242132, 0.28974575]), array([0.43053934, 0.42074114, 0.41862968, 0.4185467 , 0.41978177],\n",
      "      dtype=float32)]\n",
      "[array([0.19684036, 0.17226602, 0.15658489, 0.14523137, 0.13644871]), array([0.19684036, 0.189154  , 0.18719515, 0.18752015, 0.18894698],\n",
      "      dtype=float32)]\n",
      "alpha=0.1\n",
      "[array([0.22836   , 0.19860595, 0.17948511, 0.16556925, 0.154774  ]), array([0.22836   , 0.21873324, 0.21584608, 0.21580419, 0.21687244],\n",
      "      dtype=float32)]\n",
      "alpha=0.3\n",
      "[array([0.30251482, 0.26285811, 0.23633458, 0.21627433, 0.20060875]), array([0.30251482, 0.29098216, 0.28722772, 0.28616804, 0.28663468],\n",
      "      dtype=float32)]\n",
      "alpha=0.5\n",
      "[array([0.37245908, 0.3247248 , 0.29181764, 0.26668196, 0.24677665]), array([0.37245908, 0.36102027, 0.35725042, 0.35627496, 0.35662818],\n",
      "      dtype=float32)]\n",
      "alpha=0.7\n",
      "[array([0.41611908, 0.3651434 , 0.32947718, 0.30171934, 0.27955983]), array([0.41611907, 0.40662274, 0.40431902, 0.4041763 , 0.4051319 ],\n",
      "      dtype=float32)]\n",
      "alpha=0.9\n",
      "[array([0.43450041, 0.38131583, 0.34413031, 0.31536525, 0.29232812]), array([0.43450043, 0.4251404 , 0.4229146 , 0.42294186, 0.42411116],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "only_img = evaluations(score_mat, acc, docs, lbls, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf79e27b-e96c-496d-bc10-c57680b26523",
   "metadata": {},
   "outputs": [],
   "source": [
    "[array([0.43450041, 0.38131583, 0.34413031, 0.31536525, 0.29232812]), array([0.43450043, 0.4251404 , 0.4229146 , 0.42294186, 0.42411116], dtype=float32)]\n",
    "[array([0.50501658, 0.44281596, 0.39777996, 0.36280111, 0.3347238 ]), array([0.50501657, 0.49323103, 0.48841268, 0.48633847, 0.48577246], dtype=float32)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7b774418-586d-4c36-9dd1-1986d26fb20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_npz(f\"{corpus_dset}/only_txt.npz\", only_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d252625a-b778-4cf3-ad10-aa0725ccfba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.save_npz(f\"{corpus_dset}/only_img.npz\", only_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f88addb-43be-4ea2-a886-36a486aa8710",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
