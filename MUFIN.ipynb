{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcb8a80-6125-47d9-9e03-e614ea8e17fc",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65846a34-2ffd-4c07-aff3-c42df0fbf30d",
   "metadata": {},
   "outputs": [],
   "source": [
    "work_dir=\"/scratch/cse/phd/anz198717/XC\"\n",
    "corpus_dataset=\"MM-AmazonTitles-300K\"\n",
    "version=\"test_xc\"\n",
    "model_type=\"MufinTextXC\"\n",
    "img_model=\"ViT\"\n",
    "txt_model=\"sentencebert\"\n",
    "ranker=\"MufinXAttnRanker\"\n",
    "corpus_dset=f\"{work_dir}/Corpus/{corpus_dataset}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74452bf6-9d3f-469b-beed-9f7ac5add12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import site\n",
    "import sys\n",
    "sys.argv = f\"MUFIN\".split()\n",
    "import argparse\n",
    "site.addsitedir(f\"{work_dir}/programs/ExtremeMethods\")\n",
    "import os\n",
    "os.environ['KEEP_TOP_K'] = \"-1\"\n",
    "os.environ['RESTRICTMEM'] = \"0\"\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = \"0,1\"\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import mufin as mn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a337667-f9a7-44e1-8b72-dc11c9ee5f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description='Inference')\n",
    "params = parser.parse_args()\n",
    "params.A = 0.55\n",
    "params.B = 1.5\n",
    "\n",
    "params.data_dir = corpus_dset\n",
    "params.img_model = img_model\n",
    "params.filter_labels = \"filter_labels_test.txt\"\n",
    "params.txt_model = txt_model\n",
    "params.img_model = img_model\n",
    "params.data_path = None\n",
    "params.module = 1\n",
    "params.max_worker_thread = 6\n",
    "params.bucket = 1\n",
    "params.accumulate = 1\n",
    "params.margin = 0.3\n",
    "params.neg_sample = 3\n",
    "params.project_dim = 768\n",
    "params.n_heads = 2\n",
    "params.head_dims = 1024\n",
    "params.n_layer = 1\n",
    "params.dropout = 0.1\n",
    "params.keep_all = True\n",
    "params.batch_size = 512\n",
    "params.num_workers = 6\n",
    "params.validate = True\n",
    "params.model_out_name = \"model.pkl\"\n",
    "params.optim = \"Adam\"\n",
    "params.prefetch_factor = 2\n",
    "\"\"\"\n",
    "Adjust according to need\n",
    "\"\"\"\n",
    "params.ranker = ranker\n",
    "params.model_dir = f\"{work_dir}/models/MM-AmazonTitles-300K/{model_type}/v_{version}\"\n",
    "params.result_dir = f\"{corpus_dset}/temp\"\n",
    "params.model_fname = model_type\n",
    "params.num_labels = 1305265\n",
    "params.top_k = 100\n",
    "params.lbl_indices = np.arange(params.num_labels)\n",
    "\n",
    "params.encoder_init = None if \"PreTrained\" in model_type else \"module3/encoder.pkl\"\n",
    "os.makedirs(params.model_dir, exist_ok=True)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc6f0b-91b3-4d67-9f44-53d79c5d2ab6",
   "metadata": {},
   "source": [
    "### M1 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788c187d-1c0e-4f2f-be25-e2f84e0c3dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.module = 1\n",
    "params.num_epochs = 0\n",
    "params.surrogate_warm = 20\n",
    "params.lr = 0.02\n",
    "params.at_least = 5\n",
    "params.ignore_img = False\n",
    "params.ignore_txt = False\n",
    "params.max_csim = 0.9\n",
    "params.max_worker_thread = 10\n",
    "params.min_leaf_sz = 32\n",
    "params.min_splits = -1\n",
    "params.sampling = True\n",
    "params.warm_start = 0\n",
    "params.multi_pos = 1\n",
    "params.preload = False\n",
    "params.surrogate_warm = 1000\n",
    "params.hard_pos = False\n",
    "params.batch_size = 1023\n",
    "\n",
    "net = mn.construct_network(params)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1e39bc-a097-448c-bdf2-3b48a997da0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(corpus_dset, \"images/train.img.bin\", \"raw_data/train_map.txt\", \"trn_X_Y.txt\", \"images/test.img.bin\",\n",
    "          \"raw_data/test_map.txt\", \"tst_X_Y.txt\", \"images/label.img.bin\", \"raw_data/label_map.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b8c990-880f-43e0-8c77-33cac4fd580d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.retrain(corpus_dset, \"images/train.img.bin\", \"raw_data/train_map.txt\",\n",
    "              \"trn_X_Y.txt\", \"images/label.img.bin\", \"raw_data/label_map.txt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c16353f-60ed-4bae-9b63-2d6ca55784f6",
   "metadata": {},
   "source": [
    "## SETUP for M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993644de-0874-420d-bbf2-ba6df288b2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.module = 2\n",
    "shorty_path = f\"{params.result_dir}/module2\"\n",
    "os.makedirs(shorty_path, exist_ok=True)\n",
    "net = mn.construct_network(params)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)\n",
    "\n",
    "for mode in [\"test\", \"train\", \"label\"]:\n",
    "    tst_mat = model.predict(corpus_dset, f\"images/{mode}.img.bin\", f\"raw_data/{mode}_map.txt\", None, None, None)\n",
    "    sp.save_npz(os.path.join(shorty_path, f\"{mode}.npz\"), tst_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096bc75c-adb7-4189-8e7d-f60a7318f52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.module = 3\n",
    "\n",
    "emb_path = f\"{params.result_dir}/module3\"\n",
    "os.makedirs(emb_path, exist_ok=True)\n",
    "\n",
    "net = mn.construct_network(params)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)\n",
    "\n",
    "for mode in [\"test\", \"train\", \"label\"]:\n",
    "    tst_emb = model.extract(corpus_dset, f\"images/{mode}.img.bin\", f\"raw_data/{mode}_map.txt\")\n",
    "    for key in tst_emb.keys():\n",
    "        tst_emb[key].save(emb_path+f\"/{mode}.{key}\")\n",
    "\n",
    "encoder = model.extract_encoder()\n",
    "torch.save(encoder, os.path.join(emb_path, \"encoder.pkl\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb44f459-ebeb-4669-897f-6462db65402f",
   "metadata": {},
   "source": [
    "## M4 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85310207-4b1b-4d80-963c-bbac9d01d9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params.module = 4\n",
    "params.sample_neg = 5\n",
    "params.sample_pos = 12\n",
    "params.cosine_margin = 0.5\n",
    "params.ranker_project_dim = 768\n",
    "params.lr = 0.005\n",
    "params.n_layer = 1\n",
    "params.lr_mf_enc = 0.01\n",
    "params.lr_mf_clf = 0.1\n",
    "params.sampling = True\n",
    "params.ranker_warm = 1000\n",
    "params.num_epochs = 20\n",
    "params.batch_size = 512\n",
    "params.n_heads = 12\n",
    "params.model_out_name = f\"model_{params.ranker}.pkl\"\n",
    "\n",
    "net = mn.construct_network(params)\n",
    "optim = mn.optimizer_utils.Optimizer()\n",
    "model = mn.construct_model(params, net, optim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d9773a-edd3-4db2-b485-aa121de2d09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(corpus_dset, f\"module3/train.img.pretrained\", \"module3/train.txt.pretrained\", \"trn_X_Y.txt\", f\"module3/test.img.pretrained\", \n",
    "          \"module3/test.txt.pretrained\", \"tst_X_Y.txt\", f\"module3/label.img.pretrained\", \"module3/label.txt.pretrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e452df-68d9-4d92-b6d0-277c18a7d587",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_mat = model.predict(corpus_dset, f\"module3/test.img.pretrained\", \"module3/test.txt.pretrained\",\n",
    "                          None, f\"module3/label.img.pretrained\", \"module3/label.txt.pretrained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b5f33e",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899204d7-2bca-4aa3-9c75-0fdd1e19f46e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xclib.evaluation import xc_metrics as xm\n",
    "from xc.libs.utils import load_overlap\n",
    "from xclib.data import data_utils as du\n",
    "\n",
    "tst_y = du.read_sparse_file(f\"{corpus_dset}/tst_X_Y.txt\")\n",
    "acc = xm.Metrics(tst_y)\n",
    "docs, lbls = load_overlap(corpus_dset, \"filter_labels_test.txt\")\n",
    "def evaluations(score_dict, acc, docs, lbls, al=0.9):\n",
    "    m2 = score_dict[\"module4/m2\"]\n",
    "    m4 = score_dict[\"module4/m4\"]\n",
    "    m2[docs, lbls] = 0\n",
    "    m2.eliminate_zeros()\n",
    "    print(acc.eval(m2, K=5))\n",
    "    m4[docs, lbls] = 0\n",
    "    m4.eliminate_zeros()\n",
    "    print(acc.eval(m4, K=5))\n",
    "    for alpha in [0.1, 0.3, 0.5, 0.7, 0.9]:\n",
    "        mat = m2.copy().multiply(alpha) + m4.copy().multiply(1-alpha)\n",
    "        print(f\"alpha={alpha}\")\n",
    "        print(acc.eval(mat, K=5))\n",
    "    return m2.copy().multiply(al) + m4.copy().multiply(1-al)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f1422c-67c4-400d-a558-b45212d61dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_score_mat = evaluations(score_mat, acc, docs, lbls, 0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
